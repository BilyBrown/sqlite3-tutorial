{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from smartsheet_dataframe import get_as_df\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing Smartsheet information in variables\n",
    "shitz_token = \"wMvGniITjDFd7ClZPE44wtJGvZkM7Hg7mP7if\" #Bily's personal token to access G-A smartsheet data. Anyone can obtain their own token\n",
    "fhaid = 4523924143794052 # The ID number that references the FHA sheet\n",
    "mssid = 3005704744265604 # The ID number that references the MSS sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the FHA and MSS dataframes\n",
    "fha_df = get_as_df(type_='sheet',\n",
    "                  token=shitz_token,\n",
    "                  id_=fhaid)\n",
    "\n",
    "mss_df = get_as_df(type_='sheet',\n",
    "                  token=shitz_token,\n",
    "                  id_=mssid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_df = mss_df.loc[mss_df['UniqueID'].str.contains(\"WAR\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = war_df[['UniqueID',\n",
    "                    'Tract',\n",
    "                    'CMP',\n",
    "                    'Stand',\n",
    "                    'Acres',\n",
    "                    'Age',\n",
    "                    'County',\n",
    "                    'State',\n",
    "                    'Stand Type',\n",
    "                    'Origin',\n",
    "                    'Scheduled',\n",
    "                    'PreBA',\n",
    "                    'PreTPA',\n",
    "                    'PreGTA',\n",
    "                    'PlnBA',\n",
    "                    'PlnTPA',\n",
    "                    'PlnGTA',\n",
    "                    'Client GT',\n",
    "                    'Future GT',\n",
    "                    'Reporting Period']].copy()\n",
    "\n",
    "client_df['Reporting Period'] = client_df['Reporting Period'].fillna(0)\n",
    "client_df.loc[client_df['Reporting Period'] == \"\", 'Reporting Period'] = 0\n",
    "s = client_df.loc[pd.to_numeric(client_df['Reporting Period'], errors='coerce').isnull() & client_df['Reporting Period'].str.contains(\"RP\"), 'Reporting Period'].apply(lambda x: x.strip()[-1])\n",
    "client_df['trial'] = client_df.index.map(s)\n",
    "client_df.loc[pd.to_numeric(client_df['Reporting Period'], errors='coerce').isnull() & client_df['Reporting Period'].str.contains(\"RP\"), 'Reporting Period'] = client_df.loc[pd.to_numeric(client_df['Reporting Period'], errors='coerce').isnull() & client_df['Reporting Period'].str.contains(\"RP\"), 'trial']\n",
    "client_df['Reporting Period'] = pd.to_numeric(client_df['Reporting Period'], downcast='integer')\n",
    "client_df['Age'] = pd.to_numeric(client_df['Age'], errors='coerce', downcast='integer').fillna(0).astype(int)\n",
    "client_df.loc[pd.to_numeric(client_df['Future GT'], errors='coerce').isnull(), 'Future GT'] = 0\n",
    "client_df['Tract'] = client_df['Tract'].astype(str)\n",
    "client_df['Stand'] = client_df['Stand'].astype(str)\n",
    "client_df['Tract'] = client_df['Tract'].apply(lambda x: x.split('.')[0])\n",
    "client_df['Client GT'] = pd.to_numeric(client_df['Client GT'], errors=\"coerce\")\n",
    "client_df['Client GT'] = client_df['Client GT'].fillna(0)\n",
    "\n",
    "cols = ['PreBA', 'PreTPA', 'PreGTA', 'PlnBA', 'PlnTPA', 'PlnGTA']\n",
    "\n",
    "for x in cols:\n",
    "    client_df[x] = pd.to_numeric(client_df[x], errors='coerce', downcast='integer').fillna(-99).astype(int)\n",
    "\n",
    "client_df.drop(columns=['trial'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am thinking of creating more tables : county, state, origin, species. That way if we have to update the way somethign is spelled we just do it in one place.\n",
    "\n",
    "Maybe even tract as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = [\"Slash Pine\", \"Loblolly Pine\", 'Mixed Natural Pine', 'Hardwood Mix', 'Pine Straw', \"Other\"]\n",
    "species_dict = {'Species': species}\n",
    "species_df = pd.DataFrame(species_dict)\n",
    "species_df['SpeciesUID'] = species_df.index\n",
    "\n",
    "def species_map(x):\n",
    "    x = x.lower()\n",
    "    if \"slash\" in x:\n",
    "        return 0\n",
    "    elif \"loblol\" in x:\n",
    "        return 1\n",
    "    elif \"mixed natural\" in x:\n",
    "        return 2\n",
    "    elif \"h\" in x:\n",
    "        return 3\n",
    "    elif \"straw\" in x:\n",
    "        return 4\n",
    "    elif \"pine\" in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 5\n",
    "    \n",
    "client_df['Stand Type'] = client_df['Stand Type'].apply(lambda x: species_map(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins = ['Planted', 'Natural', 'Natural Mix', 'Other']\n",
    "origin_dict = {'Origin': origins}\n",
    "origin_df = pd.DataFrame(origin_dict)\n",
    "origin_df['OriginUID'] = origin_df.index\n",
    "\n",
    "def origin_map(x):\n",
    "    x = x.lower()\n",
    "    if \"plant\" in x:\n",
    "        return 0\n",
    "    elif \"natural mix\" in x:\n",
    "        return 2\n",
    "    elif \"nat\" in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 3\n",
    "client_df['Origin'] = client_df['Origin'].apply(lambda x: origin_map(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_intake_df = war_df[['IntakeID',\n",
    "                       'FolderID',\n",
    "                       'UniqueID',\n",
    "                       'GA_ACRES',\n",
    "                       'GA GT', # this is going to be GA total isn't it? Or does it stay as GA estimate of current GT (total minus what client says is future)\n",
    "                       'Total GT', # Does this need included? At the moment we do funny stuff with total gt and subtracting future gt to get GA current rp (above)\n",
    "                       'Notes'\n",
    "                       ]].copy()\n",
    "\n",
    "# Do I want to include a Ticketid column here or use a crossreference table?\n",
    "# Should reporting period be in here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_df = war_df[['UniqueID',\n",
    "                    'Guidance',\n",
    "                    'Expiration',\n",
    "                    'GuidanceProvider',\n",
    "                    'Status',\n",
    "                    'Completed Date'\n",
    "                    ]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intake_breaker(lst):\n",
    "    intake_lst = []\n",
    "    activity_lst = []\n",
    "    for ele in lst:\n",
    "        intake_lst.append(ele[:9])\n",
    "        activity_lst.append(ele[9:11])\n",
    "        intake_st = set(intake_lst)\n",
    "        activity_st = set(activity_lst)\n",
    "        \n",
    "    return intake_lst, activity_lst, intake_st, activity_st\n",
    "\n",
    "\n",
    "def ticketid(lst):\n",
    "    \"\"\"This function creates a ticket id based off a list of unique ids\n",
    "\n",
    "    Args:\n",
    "        lst (list): a list of unique ids that have the same Tract_Cmp_Stand from MSS\n",
    "    \"\"\"\n",
    "    if len(lst) == 0:\n",
    "        return \"ERROR, Where is your uniqueid?\"\n",
    "    elif len(lst) < 2:\n",
    "        return lst[0]\n",
    "    elif len(lst) > 1:\n",
    "        # Check to see if there are multiple intakes\n",
    "        temp_lst, activity_lst, temp_st, activity_st = intake_breaker(lst)\n",
    "        temp_lst.sort()\n",
    "        activity_lst.sort()\n",
    "        if len(temp_st) > 1:\n",
    "            return f\"{temp_lst[0]}XXXX\"\n",
    "        # If there are not multiple intakes. Check to see if there are multiple activities in the lst (Intake portion should be same for all)\n",
    "        elif len(activity_st) > 1:\n",
    "           return f\"{temp_lst[0]}XXXX\"\n",
    "       # If there is only a single activity type\n",
    "        elif len(activity_st) == 1:\n",
    "            return f\"{temp_lst[0]}{activity_lst[0]}XX\"\n",
    "        else:\n",
    "            return \"Failed within len(lst) > 1\"\n",
    "        \n",
    "    else:\n",
    "        return \"Failed at length of lst\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_inprog = war_df[war_df['Status'].isin(['OPEN', 'IN PROCESS', 'POST', 'PENDING'])].copy()\n",
    "war_inprog['Tract'] = war_inprog['Tract'].astype(str).apply(lambda x: x.split('.')[0])\n",
    "war_inprog['CMP'] = war_inprog['CMP'].astype(str).apply(lambda x: x.split('.')[0])\n",
    "war_inprog['Stand'] = war_inprog['Stand'].astype(str).apply(lambda x: x.split('.')[0])\n",
    "war_inprog['TCS'] = war_inprog['Tract'] + \"_\" + war_inprog['CMP'] + \"_\" + war_inprog['Stand']\n",
    "\n",
    "# After talking with Rob, we need to make sure that we separate out the GA and the ARB Guidance\n",
    "grouped_activities = war_inprog.groupby(['TCS', 'GuidanceProvider'])['UniqueID'].apply(list).reset_index()\n",
    "\n",
    "trial_df = grouped_activities.copy()\n",
    "trial_df['BBID'] = trial_df['UniqueID'].apply(lambda x: ticketid(x))\n",
    "\n",
    "prev_combined = war_inprog.groupby('TicketID')['TCS'].apply(set).reset_index()\n",
    "\n",
    "tcs = []\n",
    "for val in prev_combined['TCS'].loc[prev_combined['TCS'].str.len()> 1].values:\n",
    "    for item in val:\n",
    "        tcs.append(item)\n",
    "        \n",
    "ticket_id_dict = {}\n",
    "for i, row in prev_combined.loc[prev_combined['TCS'].str.len()> 1].iterrows():\n",
    "    # print(row['TicketID']) # ticket id\n",
    "    value_list = []\n",
    "    for value in row['TCS']:\n",
    "        value_list.append(value)\n",
    "    ticket_id_dict[row['TicketID']] = value_list\n",
    "    \n",
    "for k, v in ticket_id_dict.items():\n",
    "    trial_df.loc[trial_df['TCS'].isin(v), 'otherid'] = k\n",
    "\n",
    "def final_id(row):\n",
    "    if row['otherid'] != \"nan\":\n",
    "        return row['otherid']\n",
    "    else:\n",
    "        return row['BBID']\n",
    "    \n",
    "trial_df['finalid'] = trial_df[['BBID', 'otherid']].apply(final_id, axis=1)\n",
    "\n",
    "def break_list(x):\n",
    "    trial_list = []\n",
    "    for item in x:\n",
    "        for iter in item:\n",
    "            trial_list.append(iter)\n",
    "            \n",
    "    return trial_list\n",
    "\n",
    "new_ticket_df = trial_df.groupby('finalid').agg({'TCS': lambda x: list(x),\n",
    "                                 'UniqueID': lambda x: break_list(x)}).reset_index()\n",
    "\n",
    "client_for_ticket = client_df.copy()\n",
    "for id in new_ticket_df['finalid'].unique().tolist():\n",
    "    client_for_ticket.loc[client_for_ticket['UniqueID'].isin(new_ticket_df.loc[new_ticket_df['finalid'] == id, 'UniqueID'].values[0]), 'TicketID'] = id\n",
    "\n",
    "new_tcs_intake = client_for_ticket.groupby(['TicketID',\n",
    "                                            'UniqueID'])['Client GT'].sum().reset_index()\n",
    "\n",
    "old_ticket_ids = dict(zip(war_df['UniqueID'], war_df['TicketID']))\n",
    "new_tcs_intake['old_ticketids'] = new_tcs_intake['UniqueID'].map(old_ticket_ids)\n",
    "new_tcs_intake.loc[~new_tcs_intake['TicketID'].str.contains(\"WAR\"), 'TicketID'] = new_tcs_intake['old_ticketids']\n",
    "\n",
    "# Manually fix this issue where we had to deal with overlaps and SPB management\n",
    "new_tcs_intake.loc[new_tcs_intake['UniqueID'] == 'WAR231006BI02', 'TicketID'] = \"WAR230817CCXX\"\n",
    "new_tcs_intake.loc[new_tcs_intake['UniqueID'] == 'WAR240627BI01', 'TicketID'] = 'WAR230908XXXX'\n",
    "new_tcs_intake.loc[new_tcs_intake['UniqueID'] == 'WAR180518TT01', 'TicketID'] = 'WAR180518XXXX'\n",
    "new_tcs_intake.loc[new_tcs_intake['UniqueID'] == 'WAR180518TH03', 'TicketID'] = 'WAR180518XXXX'\n",
    "new_tcs_intake.loc[new_tcs_intake['UniqueID'] == 'WAR230318TXXX', 'TicketID'] = 'WAR230318TXXX'\n",
    "new_tcs_intake.loc[new_tcs_intake['UniqueID'] == 'WAR230318TH02', 'TicketID'] = 'WAR230318TXXX'\n",
    "\n",
    "ticketid_table = new_tcs_intake[['TicketID', 'UniqueID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the ticket table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TicketID</th>\n",
       "      <th>UniqueID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>WAR230908XXXX</td>\n",
       "      <td>WAR240627BI01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TicketID       UniqueID\n",
       "93  WAR230908XXXX  WAR240627BI01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticketid_table[ticketid_table['UniqueID'] == \"WAR240627BI01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\\Mill Tickets\\ARCHIVE\\WAR_RP6\n",
      "WAR_RP6_Compiled.xlsm\n",
      "P:\\Mill Tickets\\ARCHIVE\\WAR_RP7\n",
      "WAR_RP7_Compiled.xlsm\n",
      "P:\\Mill Tickets\\ARCHIVE\\WAR_RP8\n",
      "WAR_RP8_Compiled.xlsm\n",
      "P:\\Mill Tickets\\Retroactive_Ticket_imageing\\WAR\\WAR_RP2\n",
      "WAR_RP2_Compiled.xlsm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bbrown\\Anaconda3\\envs\\postgres_python\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\\Mill Tickets\\Retroactive_Ticket_imageing\\WAR\\WAR_RP3\n",
      "WAR_RP3_Compiled.xlsm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bbrown\\Anaconda3\\envs\\postgres_python\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\\Mill Tickets\\Retroactive_Ticket_imageing\\WAR\\WAR_RP4\n",
      "WAR_RP4_Compiled.xlsm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bbrown\\Anaconda3\\envs\\postgres_python\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\\Mill Tickets\\Retroactive_Ticket_imageing\\WAR\\WAR_RP5\n",
      "WAR_RP5_Compiled.xlsm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bbrown\\Anaconda3\\envs\\postgres_python\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\\Mill Tickets\\WAR_RP9\n",
      "WAR_RP9_Compiled.xlsm\n"
     ]
    }
   ],
   "source": [
    "mill_loc = r\"P:\\Mill Tickets\"\n",
    "file_pattern = \"WAR_RP*_Compiled.xlsm\"\n",
    "big_df = pd.DataFrame()\n",
    "\n",
    "mill_name = []\n",
    "for root, dirs, files in os.walk(mill_loc):\n",
    "    for file in files:\n",
    "        if \"WAR_RP\" in file and file.endswith(\"Compiled.xlsm\"):\n",
    "            if \"$\" in file:\n",
    "                pass\n",
    "            else:\n",
    "                print(root)\n",
    "                print(file)\n",
    "                df = pd.read_excel(os.path.join(root, file), sheet_name='RP_Project')\n",
    "                big_df = pd.concat([big_df, df])\n",
    "                \n",
    "\n",
    "big_df.loc[big_df['Tons (U.S)'].isnull(), 'Tons (U.S)'] = big_df.loc[big_df['Tons (U.S)'].isnull(), 'TonsUS']\n",
    "big_df['Cull Tons'].fillna(big_df['CullTons'], inplace=True)\n",
    "big_df['Accepted Tons'].fillna(big_df['AcceptedTons'], inplace=True)\n",
    "big_df['Reporting Period'].fillna(big_df['ReportingPeriod'],inplace=True)\n",
    "\n",
    "def rep_fix(x):\n",
    "    if \"RP\" in str(x):\n",
    "        return x[-1]\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "big_df['Reporting Period'] = big_df['Reporting Period'].apply(lambda x: rep_fix(x))\n",
    "big_df['Reporting Period'] = pd.to_numeric(big_df['Reporting Period'])\n",
    "\n",
    "big_df['Date'] = pd.to_datetime(big_df['Date'])\n",
    "\n",
    "mill_df = big_df[['Date',\n",
    "                  'Ticket',\n",
    "                  'Mill',\n",
    "                  'Product',\n",
    "                  'Tons (U.S)',\n",
    "                  'Cull Tons',\n",
    "                  'Accepted Tons',\n",
    "                  'Source',\n",
    "                  'Notes',\n",
    "                  'Reporting Period',\n",
    "                  'TicketID',\n",
    "                  'Week']].copy()\n",
    "\n",
    "mill_df = mill_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the expected harvest\n",
    "\n",
    "Find all activities that are Open, Pending, In Process, Post\n",
    "\n",
    "Get their ticket id\n",
    "\n",
    "Get the sum of the expected rp8 for that ticketid\n",
    "get the sum of the expected rp9 for that ticketid\n",
    "\n",
    "get the harvested volumes for those ticketids (already did this by getting the sums and translating from old ticketid to new ticketid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Step\n",
    "\n",
    "Make the base expected table\n",
    "\n",
    "I think we need to start this from the MSS_df\n",
    "\n",
    "To get us values as stated on MSS:\n",
    "- Get the Expected GT for the RP requested\n",
    "- Get the Future GT\n",
    "  - Add 1 to the RP requested\n",
    "- Groupby the new Ticket ID\n",
    "\n",
    "To Updated for RP9:\n",
    "- get all ticket ids that are open in process, pending, post\n",
    "- Get the harvested volume for those ticket ids (might have to walk from old ticketid to uniqueid to new ticketid)\n",
    "- find any remaining expected for those ticket ids\n",
    "  - Add remaining to the RP9 volume\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get harvested tons by old tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvested_tons_oldTID = mill_df[mill_df['Reporting Period'] == 8].groupby(\"TicketID\")['Tons (U.S)'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345687.7569999999"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harvested_tons_oldTID['Tons (U.S)'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get new and old TIDs that are currently in process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting harvest ids that were in RP 8 and are still \"Active\" (Potentially need updating due to harvest)\n",
    "harvest_activities = war_df[(war_df['Reporting Period'] == 8) & (war_df['Status'].isin(['IN PROCESS', \"POST\"]))]['UniqueID'].unique().tolist()\n",
    "harvest_old_ticketid = war_df[(war_df['Reporting Period'] == 8) & (war_df['Status'].isin(['IN PROCESS', \"POST\"]))]['TicketID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153119.87999999998"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how many tons are under old TIDs of activities in question\n",
    "harvested_tons_oldTID[harvested_tons_oldTID['TicketID'].isin(harvest_old_ticketid)]['Tons (U.S)'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the new TIDs based on these harvest activities\n",
    "new_ticketIDs = ticketid_table[ticketid_table['UniqueID'].isin(harvest_activities)]['TicketID'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what is in old_ticketid that is not in new_ticketIDs\n",
    "[item for item in harvest_old_ticketid if item not in new_ticketIDs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it looks like we don't have any old ticketids in the harvested file that are not in the new ticketids\n",
    "\n",
    "That doesn't mean there aren't changes of uniqueids between the two sets of ticketids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WAR220728TT01', 'WAR220728TH02']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_df[war_df['TicketID'] == \"WAR220728XXXX\"]['UniqueID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TicketID</th>\n",
       "      <th>UniqueID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>WAR220728XXXX</td>\n",
       "      <td>WAR220728TH02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>WAR220728XXXX</td>\n",
       "      <td>WAR220728TT01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TicketID       UniqueID\n",
       "202  WAR220728XXXX  WAR220728TH02\n",
       "203  WAR220728XXXX  WAR220728TT01"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticketid_table[ticketid_table['TicketID'] == \"WAR220728XXXX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in harvest_old_ticketid:\n",
    "    old_unique = war_df[war_df['TicketID'] == id]['UniqueID'].unique().tolist()\n",
    "    new_unique = ticketid_table[ticketid_table['TicketID'] == id]['UniqueID'].unique().tolist()\n",
    "    inold_notinew = [item for item in old_unique if item not in new_unique]\n",
    "    if len(inold_notinew) > 0:\n",
    "        print(id, old_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it looks like we are lucky and the new ticketids aren't messing up the accounting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- Get the expected GT for RP8 by new ticketid\n",
    "- Get the expected GT for RP9 by new ticketid\n",
    "- Update the expected RP9 GT with Rob's harvesting ruleset\n",
    "\n",
    "RP8 Expected - will be the conservative between Client and GT (in war_df it will be the \"Current RP Expected GT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_expected = pd.merge(ticketid_table, war_df[['UniqueID', 'Current RP Expected GT', 'Status', 'Future GT']], on='UniqueID', how='left')\n",
    "trial_expected = pd.merge(trial_expected, client_df[['UniqueID', 'Reporting Period']], on='UniqueID', how='left')\n",
    "war_rp8_expected = trial_expected[(trial_expected['Reporting Period'] == 8) & trial_expected['Status'].isin(['IN PROCESS', 'OPEN', 'POST'])].groupby('TicketID')['Current RP Expected GT'].sum().reset_index()\n",
    "war_rp8_expected = pd.merge(war_rp8_expected, harvested_tons_oldTID, on='TicketID', how='left')\n",
    "war_rp8_expected['Tons (U.S)'] = pd.to_numeric(war_rp8_expected['Tons (U.S)'], errors='coerce', downcast='float')\n",
    "war_rp8_expected['Tons (U.S)'].fillna(0, inplace=True)\n",
    "war_rp8_expected['Remaining'] = war_rp8_expected['Current RP Expected GT'] - war_rp8_expected['Tons (U.S)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TicketID</th>\n",
       "      <th>Current RP Expected GT</th>\n",
       "      <th>Tons (U.S)</th>\n",
       "      <th>Remaining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WAR230113TD03</td>\n",
       "      <td>7322.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WAR230113TD04</td>\n",
       "      <td>12680.0</td>\n",
       "      <td>11999.750000</td>\n",
       "      <td>680.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WAR230303TH01</td>\n",
       "      <td>4253.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WAR230318TT04</td>\n",
       "      <td>1235.96</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1235.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WAR230318TT07</td>\n",
       "      <td>828.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>828.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WAR230711TH01</td>\n",
       "      <td>15300.0</td>\n",
       "      <td>15124.259766</td>\n",
       "      <td>175.740234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WAR230712TH01</td>\n",
       "      <td>4450.0</td>\n",
       "      <td>1811.500000</td>\n",
       "      <td>2638.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WAR230712TH02</td>\n",
       "      <td>3312.39</td>\n",
       "      <td>2347.729980</td>\n",
       "      <td>964.66002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>WAR230908TH04</td>\n",
       "      <td>18043.550781</td>\n",
       "      <td>13091.679688</td>\n",
       "      <td>4951.871094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WAR231004TN01</td>\n",
       "      <td>1000.47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>WAR231006BI03</td>\n",
       "      <td>1648.693823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1648.693823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WAR231006BI04</td>\n",
       "      <td>19389.95701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19389.95701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WAR231018TH01</td>\n",
       "      <td>3317.21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3317.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WAR231107XXXX</td>\n",
       "      <td>2398.12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2398.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>WAR240109BIXX</td>\n",
       "      <td>10462.03</td>\n",
       "      <td>8699.929688</td>\n",
       "      <td>1762.100312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>WAR240618BI01</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>WAR240618BI02</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>WAR240618BI03</td>\n",
       "      <td>11630.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11630.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TicketID Current RP Expected GT    Tons (U.S)    Remaining\n",
       "0   WAR230113TD03                 7322.0      0.000000       7322.0\n",
       "1   WAR230113TD04                12680.0  11999.750000       680.25\n",
       "3   WAR230303TH01                 4253.0      0.000000       4253.0\n",
       "5   WAR230318TT04                1235.96      0.000000      1235.96\n",
       "7   WAR230318TT07                  828.0      0.000000        828.0\n",
       "9   WAR230711TH01                15300.0  15124.259766   175.740234\n",
       "10  WAR230712TH01                 4450.0   1811.500000       2638.5\n",
       "11  WAR230712TH02                3312.39   2347.729980    964.66002\n",
       "14  WAR230908TH04           18043.550781  13091.679688  4951.871094\n",
       "16  WAR231004TN01                1000.47      0.000000      1000.47\n",
       "17  WAR231006BI03            1648.693823      0.000000  1648.693823\n",
       "18  WAR231006BI04            19389.95701      0.000000  19389.95701\n",
       "20  WAR231018TH01                3317.21      0.000000      3317.21\n",
       "21  WAR231107XXXX                2398.12      0.000000      2398.12\n",
       "24  WAR240109BIXX               10462.03   8699.929688  1762.100312\n",
       "39  WAR240618BI01                  682.0      0.000000        682.0\n",
       "40  WAR240618BI02                 1724.0      0.000000       1724.0\n",
       "41  WAR240618BI03                11630.0      0.000000      11630.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_rp8_expected[war_rp8_expected['Remaining'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# war_rp8_expected.to_excel('rp8_accounting.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_rp9_expected = trial_expected[(trial_expected['Reporting Period'] == 9) & (trial_expected['Status'].isin(['OPEN', 'IN PROCESS', 'PENDING', 'POST']))].groupby('TicketID')['Current RP Expected GT'].sum().reset_index()\n",
    "war_rp9_expected_1 = trial_expected[(trial_expected['Reporting Period'] == 8) & (trial_expected['Status'].isin(['OPEN', 'IN PROCESS', 'PENDING', 'POST']))].groupby('TicketID')['Future GT'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_rp9_expected = pd.merge(war_rp9_expected, war_rp9_expected_1, on='TicketID', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TicketID</th>\n",
       "      <th>Current RP Expected GT</th>\n",
       "      <th>Future GT</th>\n",
       "      <th>RP9_Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WAR230908XXXX</td>\n",
       "      <td>28182.89</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28182.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WAR231107XXXX</td>\n",
       "      <td>9891.59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9891.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WAR240521CCXX</td>\n",
       "      <td>9814.68</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9814.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WAR240521TN01</td>\n",
       "      <td>2918.65</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2918.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAR240521TT01</td>\n",
       "      <td>6756.53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6756.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>WAR240524TT01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3943.700000</td>\n",
       "      <td>3943.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>WAR240606TH02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6161.100098</td>\n",
       "      <td>6161.100098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>WAR240618BI01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>WAR240618BI02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>WAR240618BI03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TicketID  Current RP Expected GT    Future GT  RP9_Expected\n",
       "0   WAR230908XXXX                28182.89     0.000000  28182.890000\n",
       "1   WAR231107XXXX                 9891.59     0.000000   9891.590000\n",
       "2   WAR240521CCXX                 9814.68     0.000000   9814.680000\n",
       "3   WAR240521TN01                 2918.65     0.000000   2918.650000\n",
       "4   WAR240521TT01                 6756.53     0.000000   6756.530000\n",
       "..            ...                     ...          ...           ...\n",
       "65  WAR240524TT01                    0.00  3943.700000   3943.700000\n",
       "66  WAR240606TH02                    0.00  6161.100098   6161.100098\n",
       "67  WAR240618BI01                    0.00     0.000000      0.000000\n",
       "68  WAR240618BI02                    0.00     0.000000      0.000000\n",
       "69  WAR240618BI03                    0.00     0.000000      0.000000\n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_rp9_expected['Current RP Expected GT'] = pd.to_numeric(war_rp9_expected['Current RP Expected GT'], errors='coerce', downcast='float')\n",
    "war_rp9_expected['Future GT'] = pd.to_numeric(war_rp9_expected['Future GT'], errors='coerce', downcast='float')\n",
    "war_rp9_expected.fillna(0, inplace=True)\n",
    "war_rp9_expected['RP9_Expected'] = war_rp9_expected['Current RP Expected GT'] + war_rp9_expected['Future GT']\n",
    "war_rp9_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_rp9_expected.to_excel(\"rp9_investigate.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TicketID</th>\n",
       "      <th>UniqueID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>WAR230817CCXX</td>\n",
       "      <td>WAR231006BI02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TicketID       UniqueID\n",
       "19  WAR230817CCXX  WAR231006BI02"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticketid_table[ticketid_table['UniqueID'] == 'WAR231006BI02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticketid_table.to_excel(\"TicketID_Table.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_tcs_intake.to_excel(\"new-to-oldtids.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ticket_df.to_excel(\"ticketlookip_v2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_trial = war_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_trial = war_trial[war_trial['Status'].isin(['IN PROCESS', 'OPEN', 'PENDING', 'POST'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_trial['Current RP Expected GT'] = pd.to_numeric(war_trial['Current RP Expected GT'], errors='coerce').fillna(0)\n",
    "war_trial['Future GT'] = pd.to_numeric(war_trial['Future GT'], errors='coerce').fillna(0)\n",
    "war_trial['Total GT'] = pd.to_numeric(war_trial['Total GT'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_trial = war_trial[['TicketID', 'Current RP Expected GT', 'Future GT', 'Total GT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534629.786834"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_trial['Total GT'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_totals = war_trial.groupby('TicketID').agg({\n",
    "    \"Current RP Expected GT\": \"sum\",\n",
    "    'Future GT': \"sum\",\n",
    "    \"Total GT\": \"sum\"\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TicketID</th>\n",
       "      <th>Current RP Expected GT</th>\n",
       "      <th>Future GT</th>\n",
       "      <th>Total GT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WAR230113TD03</td>\n",
       "      <td>7322.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7322.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WAR230113TD04</td>\n",
       "      <td>12680.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12680.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WAR230203TTXX</td>\n",
       "      <td>4186.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WAR230303TH01</td>\n",
       "      <td>4253.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4253.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAR230318CC05</td>\n",
       "      <td>4256.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4256.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>WAR241025HD09</td>\n",
       "      <td>4781.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4781.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>WAR241025HD16</td>\n",
       "      <td>5174.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5180.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>WAR241025HD17</td>\n",
       "      <td>4689.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4690.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>WAR241025HDXX</td>\n",
       "      <td>21772.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21772.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>WAR241025TT01</td>\n",
       "      <td>4528.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4528.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TicketID  Current RP Expected GT  Future GT  Total GT\n",
       "0   WAR230113TD03                 7322.00        0.0   7322.00\n",
       "1   WAR230113TD04                12680.00        0.0  12680.00\n",
       "2   WAR230203TTXX                 4186.00        0.0      0.00\n",
       "3   WAR230303TH01                 4253.00        0.0   4253.00\n",
       "4   WAR230318CC05                 4256.00        0.0   4256.00\n",
       "..            ...                     ...        ...       ...\n",
       "65  WAR241025HD09                 4781.69        0.0   4781.69\n",
       "66  WAR241025HD16                 5174.26        0.0   5180.00\n",
       "67  WAR241025HD17                 4689.54        0.0   4690.00\n",
       "68  WAR241025HDXX                21772.72        0.0  21772.72\n",
       "69  WAR241025TT01                 4528.00        0.0   4528.00\n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_harvested = mill_df.groupby(['TicketID']).agg({'Tons (U.S)': \"sum\",\n",
    "                                                      'Date': \"max\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tons (U.S)</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TicketID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WAR180206TH01</th>\n",
       "      <td>5145.14</td>\n",
       "      <td>2018-10-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAR180206TH02</th>\n",
       "      <td>6705.43</td>\n",
       "      <td>2018-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAR180206TH03</th>\n",
       "      <td>5644.90</td>\n",
       "      <td>2019-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAR180518TH01</th>\n",
       "      <td>2514.31</td>\n",
       "      <td>2018-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAR180518TH02</th>\n",
       "      <td>2258.22</td>\n",
       "      <td>2018-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAR240302TT03</th>\n",
       "      <td>2510.22</td>\n",
       "      <td>2024-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAR240417TH01</th>\n",
       "      <td>3893.61</td>\n",
       "      <td>2024-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAR240606TH02</th>\n",
       "      <td>5270.54</td>\n",
       "      <td>2024-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAR240618BI03</th>\n",
       "      <td>14266.20</td>\n",
       "      <td>2024-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAR240627BI02</th>\n",
       "      <td>15583.27</td>\n",
       "      <td>2024-09-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Tons (U.S)       Date\n",
       "TicketID                            \n",
       "WAR180206TH01     5145.14 2018-10-16\n",
       "WAR180206TH02     6705.43 2018-07-26\n",
       "WAR180206TH03     5644.90 2019-05-15\n",
       "WAR180518TH01     2514.31 2018-10-03\n",
       "WAR180518TH02     2258.22 2018-08-16\n",
       "...                   ...        ...\n",
       "WAR240302TT03     2510.22 2024-06-14\n",
       "WAR240417TH01     3893.61 2024-08-10\n",
       "WAR240606TH02     5270.54 2024-06-26\n",
       "WAR240618BI03    14266.20 2024-10-17\n",
       "WAR240627BI02    15583.27 2024-09-20\n",
       "\n",
       "[106 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticket_harvested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_figure = pd.merge(war_totals, ticket_harvested, on='TicketID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_figure.to_excel(\"war_total_expected_3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ticket_df['tcsLookup'] = new_ticket_df['TCS'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ticket_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mill_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build DB\n",
    "\n",
    "All tables need a primary key column created/inserted\n",
    "\n",
    "- [x] Client Provided info\n",
    "- [x] GA Gas intake info\n",
    "- [x] ticketid table\n",
    "- [x] ticketid/uniqueid lookup table - Need to change the ticketid to the ticketid table primary key (map)\n",
    "- [x] tree species table\n",
    "- [x] tree origin table\n",
    "- [x] RP expected table\n",
    "- [/] Mill_ticket_table - needs edited/3NF\n",
    "- [/] Status table - need to map guidance provider primary key\n",
    "- [ ] Guidance provider table\n",
    "- [ ] Activity_Plots Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be just ticketid as a foreign key and then the index become a column that is the primary key and that will be referenced elsewhere.\n",
    "ticketid_lookup_table = ticketid_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticketids = ticketid_table['TicketID'].unique().tolist()\n",
    "ticketids_dict = {}\n",
    "ticketids_dict['TicketID'] = ticketids\n",
    "ticket_id_df = pd.DataFrame(ticketids_dict)\n",
    "ticket_id_df['TicketUID'] = ticket_id_df.index\n",
    "ticket_mapper = dict(zip(ticket_id_df['TicketID'], ticket_id_df['TicketUID']))\n",
    "ticketid_lookup_table['TicketUID'] = ticketid_lookup_table['TicketID'].map(ticket_mapper)\n",
    "ticketid_lookup_table.drop(columns='TicketID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticketid_lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_intake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mill_df.loc[mill_df['TicketID'] == \"WAR18051XXXX\", 'TicketID'] = \"WAR180518XXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mill_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance_list = status_df['GuidanceProvider'].unique().tolist()\n",
    "guidance_dict = {}\n",
    "guidance_dict['guidance_provider'] = guidance_list\n",
    "guidance_df = pd.DataFrame(guidance_dict)\n",
    "guidance_df['guidance_uid'] = guidance_df.index\n",
    "guidance_mapper = dict(zip(guidance_df['guidance_provider'], guidance_df['guidance_uid']))\n",
    "status_df['guidance_provider'] = status_df['GuidanceProvider'].map(guidance_mapper)\n",
    "status_df.drop(columns=['GuidanceProvider'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_mill_df = mill_df.copy()\n",
    "trial_mill_df['ticket_uid'] = pd.to_numeric(trial_mill_df['TicketID'].map(ticket_mapper), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticketid_lookup_table[ticketid_lookup_table['TicketUID'] == 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_mill_df[trial_mill_df['ticket_uid'].isna()]['TicketID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force it to work\n",
    "trial_mill_df.loc[trial_mill_df['TicketID'] == 'WAR230818TH01', 'ticket_uid'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_mill_df.drop(columns=['TicketID'], inplace=True)\n",
    "trial_mill_df['ticket_uid'] = trial_mill_df['ticket_uid'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_mill_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try making a db and populating it with these tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('./WAR_RP9_InProcess/trial-db/Harvest.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I need to work on naming conventions and making sure everything has a primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df.columns = [x.lower() for x in client_df.columns]\n",
    "client_df.columns = [x.replace(' ', '_') for x in client_df.columns]\n",
    "client_df['id'] = client_df['uniqueid']\n",
    "client_df.drop(columns=['uniqueid'],inplace=True)\n",
    "client_df = client_df[['id', 'tract', 'cmp', 'stand', 'acres', 'age', 'county', 'state', 'stand_type', 'origin', 'scheduled', 'preba', 'pretpa', 'pregta',\n",
    "                       'plnba', 'plntpa', 'plngta', 'client_gt', 'future_gt', 'reporting_period']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df['acres'] = pd.to_numeric(client_df['acres'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df.to_sql('client_intake', conn, if_exists='replace',index=False, dtype={'id': 'TEXT PRIMARY KEY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_intake_df.columns = [x.lower().replace(' ', '_') for x in ga_intake_df.columns]\n",
    "ga_intake_df.rename(columns={'uniqueid': 'id'},inplace=True)\n",
    "ga_intake_df = ga_intake_df[['id', 'intakeid', 'folderid', 'ga_acres', 'ga_gt', 'total_gt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_intake_df.to_sql('ga_intake', conn, if_exists='replace', index=False, dtype={'id': 'TEXT PRIMARY KEY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticketid_lookup_table.rename(columns={'TicketUID': 'id',\n",
    "                                      'UniqueID': 'activity_id'}, inplace=True)\n",
    "ticketid_lookup_table.to_sql('ticketid_lookup_activityid', conn, if_exists='replace', index=False, dtype={'activityid': 'TEXT PRIMARY KEY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_id_df.rename(columns={'TicketUID': 'id',\n",
    "                             'TicketID' : 'ticketid'},inplace=True)\n",
    "ticket_id_df.to_sql('ticketid', conn, if_exists='replace', index=False, dtype={'id': 'INTEGER PRIMARY KEY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_df.rename(columns={\"SpeciesUID\": \"id\",\n",
    "                           'Species': 'species'}, inplace=True)\n",
    "species_df.to_sql('species', conn, if_exists='replace', index=False, dtype={'id': 'INTEGER PRIMARY KEY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_df.rename(columns={'OriginUID': 'id',\n",
    "                          'Origin': 'origin'}, inplace=True)\n",
    "origin_df.to_sql('origin', conn, if_exists='replace', index=False, dtype={'id': 'INTEGER PRIMARY KEY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_expected_df = pd.read_csv('volume_expected_table_241030.csv')\n",
    "volume_expected_df['id'] = volume_expected_df.index\n",
    "volume_expected_df['trial_tickid'] = volume_expected_df['TicketID'].map(ticket_mapper)\n",
    "volume_expected_df.drop(columns=['TicketID'], inplace=True)\n",
    "volume_expected_df.rename(columns={'trial_tickid': 'ticketid',\n",
    "                                   'Reporting Period': 'reporting_period',\n",
    "                                   'Current RP Expected GT': 'expected_gt'},inplace=True)\n",
    "# Have to force one ticketid because of a recent harvest\n",
    "volume_expected_df['ticketid'].fillna(12, inplace=True)\n",
    "volume_expected_df.to_sql('volume_expected', conn, if_exists='replace', index=False, dtype={'id': 'INTEGER PRIMARY KEY',\n",
    "                                                                                            'ticketid': 'INTEGER'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for the mill ticket normalization\n",
    "# Normalize the Weeks column.\n",
    "# Normalize the source column\n",
    "# Normalize the Mill column\n",
    "# Normalize the Product column\n",
    "trial_mill_df['Mill'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_mill_df['Product'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postgres_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
