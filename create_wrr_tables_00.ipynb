{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from smartsheet_dataframe import get_as_df\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing Smartsheet information in variables\n",
    "shitz_token = \"wMvGniITjDFd7ClZPE44wtJGvZkM7Hg7mP7if\" #Bily's personal token to access G-A smartsheet data. Anyone can obtain their own token\n",
    "fhaid = 4523924143794052 # The ID number that references the FHA sheet\n",
    "mssid = 3005704744265604 # The ID number that references the MSS sheet\n",
    "\n",
    "# Creating the FHA and MSS dataframes\n",
    "fha_df = get_as_df(type_='sheet',\n",
    "                  token=shitz_token,\n",
    "                  id_=fhaid)\n",
    "\n",
    "mss_df = get_as_df(type_='sheet',\n",
    "                  token=shitz_token,\n",
    "                  id_=mssid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrr_df = mss_df.loc[mss_df['UniqueID'].str.contains(\"WRR\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = wrr_df[['UniqueID',\n",
    "                    'Tract',\n",
    "                    'CMP',\n",
    "                    'Stand',\n",
    "                    'Acres',\n",
    "                    'Age',\n",
    "                    'County',\n",
    "                    'State',\n",
    "                    'Stand Type',\n",
    "                    'Origin',\n",
    "                    'Scheduled',\n",
    "                    'PreBA',\n",
    "                    'PreTPA',\n",
    "                    'PreGTA',\n",
    "                    'PlnBA',\n",
    "                    'PlnTPA',\n",
    "                    'PlnGTA',\n",
    "                    'Client GT',\n",
    "                    'Future GT',\n",
    "                    'Reporting Period']].copy()\n",
    "\n",
    "client_df['Reporting Period'] = client_df['Reporting Period'].fillna(0)\n",
    "client_df.loc[client_df['Reporting Period'] == \"\", 'Reporting Period'] = 0\n",
    "s = client_df.loc[pd.to_numeric(client_df['Reporting Period'], errors='coerce').isnull() & client_df['Reporting Period'].str.contains(\"RP\"), 'Reporting Period'].apply(lambda x: x.strip()[-1])\n",
    "client_df['trial'] = client_df.index.map(s)\n",
    "client_df.loc[pd.to_numeric(client_df['Reporting Period'], errors='coerce').isnull() & client_df['Reporting Period'].str.contains(\"RP\"), 'Reporting Period'] = client_df.loc[pd.to_numeric(client_df['Reporting Period'], errors='coerce').isnull() & client_df['Reporting Period'].str.contains(\"RP\"), 'trial']\n",
    "client_df['Reporting Period'] = pd.to_numeric(client_df['Reporting Period'], downcast='integer')\n",
    "client_df['Age'] = pd.to_numeric(client_df['Age'], errors='coerce', downcast='integer').fillna(0).astype(int)\n",
    "client_df.loc[pd.to_numeric(client_df['Future GT'], errors='coerce').isnull(), 'Future GT'] = 0\n",
    "client_df['Tract'] = client_df['Tract'].astype(str)\n",
    "client_df['Stand'] = client_df['Stand'].astype(str)\n",
    "client_df['Tract'] = client_df['Tract'].apply(lambda x: x.split('.')[0])\n",
    "client_df['Client GT'] = pd.to_numeric(client_df['Client GT'], errors=\"coerce\")\n",
    "client_df['Client GT'] = client_df['Client GT'].fillna(0)\n",
    "\n",
    "cols = ['PreBA', 'PreTPA', 'PreGTA', 'PlnBA', 'PlnTPA', 'PlnGTA']\n",
    "\n",
    "for x in cols:\n",
    "    client_df[x] = pd.to_numeric(client_df[x], errors='coerce', downcast='integer').fillna(-99).astype(int)\n",
    "\n",
    "client_df.drop(columns=['trial'],inplace=True)\n",
    "\n",
    "\n",
    "# Normalize species\n",
    "\n",
    "species = [\"Slash Pine\", \"Loblolly Pine\", 'Mixed Natural Pine', 'Hardwood Mix', 'Pine Straw', \"Other\"]\n",
    "species_dict = {'Species': species}\n",
    "species_df = pd.DataFrame(species_dict)\n",
    "species_df['SpeciesUID'] = species_df.index\n",
    "\n",
    "def species_map(x):\n",
    "    x = x.lower()\n",
    "    if \"slash\" in x:\n",
    "        return 0\n",
    "    elif \"loblol\" in x:\n",
    "        return 1\n",
    "    elif \"mixed natural\" in x:\n",
    "        return 2\n",
    "    elif \"h\" in x:\n",
    "        return 3\n",
    "    elif \"straw\" in x:\n",
    "        return 4\n",
    "    \n",
    "    elif \"pine\" in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 5\n",
    "    \n",
    "client_df['Stand Type'] = client_df['Stand Type'].apply(lambda x: species_map(x))\n",
    "\n",
    "# Normalize Origin\n",
    "\n",
    "origins = ['Planted', 'Natural', 'Natural Mix', 'Other']\n",
    "origin_dict = {'Origin': origins}\n",
    "origin_df = pd.DataFrame(origin_dict)\n",
    "origin_df['OriginUID'] = origin_df.index\n",
    "\n",
    "def origin_map(x):\n",
    "    x = x.lower()\n",
    "    if \"plant\" in x:\n",
    "        return 0\n",
    "    elif \"natural mix\" in x:\n",
    "        return 2\n",
    "    elif \"nat\" in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 3\n",
    "client_df['Origin'] = client_df['Origin'].apply(lambda x: origin_map(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclient_df.columns = [x.lower() for x in client_df.columns]\\nclient_df.columns = [x.replace(' ', '_') for x in client_df.columns]\\nclient_df['id'] = client_df['uniqueid']\\nclient_df.drop(columns=['uniqueid'],inplace=True)\\nclient_df = client_df[['id', 'tract', 'cmp', 'stand', 'acres', 'age', 'county', 'state', 'stand_type', 'origin', 'scheduled', 'preba', 'pretpa', 'pregta',\\n                       'plnba', 'plntpa', 'plngta', 'client_gt', 'future_gt', 'reporting_period']]\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "client_df.columns = [x.lower() for x in client_df.columns]\n",
    "client_df.columns = [x.replace(' ', '_') for x in client_df.columns]\n",
    "client_df['id'] = client_df['uniqueid']\n",
    "client_df.drop(columns=['uniqueid'],inplace=True)\n",
    "client_df = client_df[['id', 'tract', 'cmp', 'stand', 'acres', 'age', 'county', 'state', 'stand_type', 'origin', 'scheduled', 'preba', 'pretpa', 'pregta',\n",
    "                       'plnba', 'plntpa', 'plngta', 'client_gt', 'future_gt', 'reporting_period']]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_intake_df = wrr_df[['IntakeID',\n",
    "                       'FolderID',\n",
    "                       'UniqueID',\n",
    "                       'GA_ACRES',\n",
    "                       'GA GT', # this is going to be GA total isn't it? Or does it stay as GA estimate of current GT (total minus what client says is future)\n",
    "                       'Total GT', # Does this need included? At the moment we do funny stuff with total gt and subtracting future gt to get GA current rp (above)\n",
    "                       'Notes'\n",
    "                       ]].copy()\n",
    "\n",
    "# Do I want to include a Ticketid column here or use a crossreference table?\n",
    "# Should reporting period be in here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_df = wrr_df[['UniqueID',\n",
    "                    'Guidance',\n",
    "                    'Expiration',\n",
    "                    'GuidanceProvider',\n",
    "                    'Status',\n",
    "                    'Completed Date'\n",
    "                    ]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intake_breaker(lst):\n",
    "    intake_lst = []\n",
    "    activity_lst = []\n",
    "    for ele in lst:\n",
    "        intake_lst.append(ele[:9])\n",
    "        activity_lst.append(ele[9:11])\n",
    "        intake_st = set(intake_lst)\n",
    "        activity_st = set(activity_lst)\n",
    "        \n",
    "    return intake_lst, activity_lst, intake_st, activity_st\n",
    "\n",
    "\n",
    "def ticketid(lst):\n",
    "    \"\"\"This function creates a ticket id based off a list of unique ids\n",
    "\n",
    "    Args:\n",
    "        lst (list): a list of unique ids that have the same Tract_Cmp_Stand from MSS\n",
    "    \"\"\"\n",
    "    if len(lst) == 0:\n",
    "        return \"ERROR, Where is your uniqueid?\"\n",
    "    elif len(lst) < 2:\n",
    "        return lst[0]\n",
    "    elif len(lst) > 1:\n",
    "        # Check to see if there are multiple intakes\n",
    "        temp_lst, activity_lst, temp_st, activity_st = intake_breaker(lst)\n",
    "        temp_lst.sort()\n",
    "        activity_lst.sort()\n",
    "        if len(temp_st) > 1:\n",
    "            return f\"{temp_lst[0]}XXXX\"\n",
    "        # If there are not multiple intakes. Check to see if there are multiple activities in the lst (Intake portion should be same for all)\n",
    "        elif len(activity_st) > 1:\n",
    "           return f\"{temp_lst[0]}XXXX\"\n",
    "       # If there is only a single activity type\n",
    "        elif len(activity_st) == 1:\n",
    "            return f\"{temp_lst[0]}{activity_lst[0]}XX\"\n",
    "        else:\n",
    "            return \"Failed within len(lst) > 1\"\n",
    "        \n",
    "    else:\n",
    "        return \"Failed at length of lst\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrr_inprog = wrr_df[wrr_df['Status'].isin(['OPEN', 'IN PROCESS', 'POST', 'PENDING'])].copy()\n",
    "wrr_inprog['Tract'] = wrr_inprog['Tract'].astype(str).apply(lambda x: x.split('.')[0])\n",
    "wrr_inprog['CMP'] = wrr_inprog['CMP'].astype(str).apply(lambda x: x.split('.')[0])\n",
    "wrr_inprog['Stand'] = wrr_inprog['Stand'].astype(str).apply(lambda x: x.split('.')[0])\n",
    "wrr_inprog['TCS'] = wrr_inprog['Tract'] + \"_\" + wrr_inprog['CMP'] + \"_\" + wrr_inprog['Stand']\n",
    "\n",
    "# After talking with Rob, we need to make sure that we separate out the GA and the ARB Guidance\n",
    "grouped_activities = wrr_inprog.groupby(['TCS', 'GuidanceProvider'])['UniqueID'].apply(list).reset_index()\n",
    "\n",
    "trial_df = grouped_activities.copy()\n",
    "trial_df['BBID'] = trial_df['UniqueID'].apply(lambda x: ticketid(x))\n",
    "\n",
    "prev_combined = wrr_inprog.groupby('TicketID')['TCS'].apply(set).reset_index()\n",
    "\n",
    "tcs = []\n",
    "for val in prev_combined['TCS'].loc[prev_combined['TCS'].str.len()> 1].values:\n",
    "    for item in val:\n",
    "        tcs.append(item)\n",
    "\n",
    "# looking for TCS combinations in previous ticketids        \n",
    "ticket_id_dict = {}\n",
    "for i, row in prev_combined.loc[prev_combined['TCS'].str.len()> 1].iterrows():\n",
    "    # print(row['TicketID']) # ticket id\n",
    "    value_list = []\n",
    "    for value in row['TCS']:\n",
    "        value_list.append(value)\n",
    "    ticket_id_dict[row['TicketID']] = value_list\n",
    "if len(ticket_id_dict) > 0:\n",
    "    for k, v in ticket_id_dict.items():\n",
    "        trial_df.loc[trial_df['TCS'].isin(v), 'otherid'] = k\n",
    "else:\n",
    "    trial_df['otherid'] = None\n",
    "    \n",
    "\n",
    "def final_id(row):\n",
    "    if row['otherid'] != None:\n",
    "        return row['otherid']\n",
    "    else:\n",
    "        return row['BBID']\n",
    "    \n",
    "trial_df['finalid'] = trial_df[['BBID', 'otherid']].apply(final_id, axis=1)\n",
    "\n",
    "def break_list(x):\n",
    "    trial_list = []\n",
    "    for item in x:\n",
    "        for iter in item:\n",
    "            trial_list.append(iter)\n",
    "            \n",
    "    return trial_list\n",
    "\n",
    "new_ticket_df = trial_df.groupby('finalid').agg({'TCS': lambda x: list(x),\n",
    "                                 'UniqueID': lambda x: break_list(x)}).reset_index()\n",
    "\n",
    "client_for_ticket = client_df.copy()\n",
    "for id in new_ticket_df['finalid'].unique().tolist():\n",
    "    client_for_ticket.loc[client_for_ticket['UniqueID'].isin(new_ticket_df.loc[new_ticket_df['finalid'] == id, 'UniqueID'].values[0]), 'TicketID'] = id\n",
    "\n",
    "new_tcs_intake = client_for_ticket.groupby(['TicketID',\n",
    "                                            'UniqueID'])['Client GT'].sum().reset_index()\n",
    "\n",
    "old_ticket_ids = dict(zip(wrr_df['UniqueID'], wrr_df['TicketID']))\n",
    "new_tcs_intake['old_ticketids'] = new_tcs_intake['UniqueID'].map(old_ticket_ids)\n",
    "new_tcs_intake.loc[~new_tcs_intake['TicketID'].str.contains(\"WAR\"), 'TicketID'] = new_tcs_intake['old_ticketids']\n",
    "\n",
    "\n",
    "ticketid_table = new_tcs_intake[['TicketID', 'UniqueID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TicketID</th>\n",
       "      <th>UniqueID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>WRR240101CCXX</td>\n",
       "      <td>WRR240101CC01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WRR240101CCXX</td>\n",
       "      <td>WRR240101CC02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WRR240101CCXX</td>\n",
       "      <td>WRR240101CC03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317AH24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>WRR210317TH23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>WRR210325XXXX</td>\n",
       "      <td>WRR210325AH01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>WRR210325XXXX</td>\n",
       "      <td>WRR210325HD01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>WRR210325XXXX</td>\n",
       "      <td>WRR210325HD02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>WRR210325XXXX</td>\n",
       "      <td>WRR210325HD03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>WRR210325XXXX</td>\n",
       "      <td>WRR210325HD04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>WRR210325XXXX</td>\n",
       "      <td>WRR210325HD05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>WRR210325XXXX</td>\n",
       "      <td>WRR210325TH01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>WRR210325XXXX</td>\n",
       "      <td>WRR210325TH02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>WRR210325XXXX</td>\n",
       "      <td>WRR210325TH03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>WRR210325XXXX</td>\n",
       "      <td>WRR210325TH04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>WRR230829CCXX</td>\n",
       "      <td>WRR230829CC01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>WRR230829CCXX</td>\n",
       "      <td>WRR230829CC02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>WRR230829CCXX</td>\n",
       "      <td>WRR230829CC03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>WRR231227CCXX</td>\n",
       "      <td>WRR231227CC01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>WRR231227CCXX</td>\n",
       "      <td>WRR231227CC02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>WRR231227CCXX</td>\n",
       "      <td>WRR231227CC03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>WRR231227CCXX</td>\n",
       "      <td>WRR231227CC04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>WRR231227CCXX</td>\n",
       "      <td>WRR231227CC05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TicketID       UniqueID\n",
       "14   WRR240101CCXX  WRR240101CC01\n",
       "15   WRR240101CCXX  WRR240101CC02\n",
       "16   WRR240101CCXX  WRR240101CC03\n",
       "132  WRR210317XXXX  WRR210317AH24\n",
       "133  WRR210317XXXX  WRR210317TH01\n",
       "134  WRR210317XXXX  WRR210317TH02\n",
       "135  WRR210317XXXX  WRR210317TH03\n",
       "136  WRR210317XXXX  WRR210317TH04\n",
       "137  WRR210317XXXX  WRR210317TH05\n",
       "138  WRR210317XXXX  WRR210317TH06\n",
       "139  WRR210317XXXX  WRR210317TH07\n",
       "140  WRR210317XXXX  WRR210317TH08\n",
       "141  WRR210317XXXX  WRR210317TH09\n",
       "142  WRR210317XXXX  WRR210317TH10\n",
       "143  WRR210317XXXX  WRR210317TH11\n",
       "144  WRR210317XXXX  WRR210317TH12\n",
       "145  WRR210317XXXX  WRR210317TH13\n",
       "146  WRR210317XXXX  WRR210317TH14\n",
       "147  WRR210317XXXX  WRR210317TH15\n",
       "148  WRR210317XXXX  WRR210317TH16\n",
       "149  WRR210317XXXX  WRR210317TH17\n",
       "150  WRR210317XXXX  WRR210317TH18\n",
       "151  WRR210317XXXX  WRR210317TH19\n",
       "152  WRR210317XXXX  WRR210317TH20\n",
       "153  WRR210317XXXX  WRR210317TH21\n",
       "154  WRR210317XXXX  WRR210317TH22\n",
       "155  WRR210317XXXX  WRR210317TH23\n",
       "162  WRR210325XXXX  WRR210325AH01\n",
       "163  WRR210325XXXX  WRR210325HD01\n",
       "164  WRR210325XXXX  WRR210325HD02\n",
       "165  WRR210325XXXX  WRR210325HD03\n",
       "166  WRR210325XXXX  WRR210325HD04\n",
       "167  WRR210325XXXX  WRR210325HD05\n",
       "168  WRR210325XXXX  WRR210325TH01\n",
       "169  WRR210325XXXX  WRR210325TH02\n",
       "170  WRR210325XXXX  WRR210325TH03\n",
       "171  WRR210325XXXX  WRR210325TH04\n",
       "241  WRR230829CCXX  WRR230829CC01\n",
       "242  WRR230829CCXX  WRR230829CC02\n",
       "243  WRR230829CCXX  WRR230829CC03\n",
       "255  WRR231227CCXX  WRR231227CC01\n",
       "256  WRR231227CCXX  WRR231227CC02\n",
       "257  WRR231227CCXX  WRR231227CC03\n",
       "258  WRR231227CCXX  WRR231227CC04\n",
       "259  WRR231227CCXX  WRR231227CC05"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticketid_table[ticketid_table['TicketID'].str.contains(\"X\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the mill tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\\Mill Tickets\\ARCHIVE\\WRR_RP5\n",
      "WRR_RP5_Compiled.xlsm\n",
      "P:\\Mill Tickets\\ARCHIVE\\WRR_RP6\n",
      "WRR_RP6_Compiled.xlsm\n",
      "P:\\Mill Tickets\\ARCHIVE\\WRR_RP7\n",
      "WRR_RP7_Compiled.xlsm\n",
      "P:\\Mill Tickets\\WRR_RP8\n",
      "WRR_RP8_Compiled.xlsm\n"
     ]
    }
   ],
   "source": [
    "mill_loc = r\"P:\\Mill Tickets\"\n",
    "file_pattern = \"WRR_RP*_Compiled.xlsm\"\n",
    "big_df = pd.DataFrame()\n",
    "\n",
    "mill_name = []\n",
    "for root, dirs, files in os.walk(mill_loc):\n",
    "    for file in files:\n",
    "        if \"WRR_RP\" in file and file.endswith(\"Compiled.xlsm\"):\n",
    "            if \"$\" in file:\n",
    "                pass\n",
    "            else:\n",
    "                print(root)\n",
    "                print(file)\n",
    "                df = pd.read_excel(os.path.join(root, file), sheet_name='RP_Project')\n",
    "                big_df = pd.concat([big_df, df])\n",
    "                \n",
    "\n",
    "# big_df.loc[big_df['Tons (U.S)'].isnull(), 'Tons (U.S)'] = big_df.loc[big_df['Tons (U.S)'].isnull(), 'TonsUS']\n",
    "# big_df['Cull Tons'].fillna(big_df['CullTons'], inplace=True)\n",
    "# big_df['Accepted Tons'].fillna(big_df['AcceptedTons'], inplace=True)\n",
    "# big_df['Reporting Period'].fillna(big_df['ReportingPeriod'],inplace=True)\n",
    "\n",
    "def rep_fix(x):\n",
    "    if \"RP\" in str(x):\n",
    "        return x[-1]\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "big_df['Reporting Period'] = big_df['Reporting Period'].apply(lambda x: rep_fix(x))\n",
    "big_df['Reporting Period'] = pd.to_numeric(big_df['Reporting Period'], errors='coerce')\n",
    "\n",
    "big_df['Date'] = pd.to_datetime(big_df['Date'])\n",
    "\n",
    "mill_df = big_df[['Date',\n",
    "                  'Ticket',\n",
    "                  'Mill',\n",
    "                  'Product',\n",
    "                  'Tons (U.S)',\n",
    "                  'Cull Tons',\n",
    "                  'Accepted Tons',\n",
    "                  'Source',\n",
    "                  'Notes',\n",
    "                  'Reporting Period',\n",
    "                  'TicketID',\n",
    "                  'Week']].copy()\n",
    "\n",
    "mill_df = mill_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Mill</th>\n",
       "      <th>Product</th>\n",
       "      <th>Tons (U.S)</th>\n",
       "      <th>Cull Tons</th>\n",
       "      <th>Accepted Tons</th>\n",
       "      <th>Source</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Reporting Period</th>\n",
       "      <th>TicketID</th>\n",
       "      <th>Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>875937</td>\n",
       "      <td>Georgia-Pacific Corporation - Cedar Springs Pa...</td>\n",
       "      <td>PPW</td>\n",
       "      <td>23.27</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.270</td>\n",
       "      <td>Mayhaw_Week 10.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>875841</td>\n",
       "      <td>Georgia-Pacific Corporation - Cedar Springs Pa...</td>\n",
       "      <td>PPW</td>\n",
       "      <td>23.86</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.860</td>\n",
       "      <td>Mayhaw_Week 10.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>875787</td>\n",
       "      <td>Georgia-Pacific Corporation - Cedar Springs Pa...</td>\n",
       "      <td>PPW</td>\n",
       "      <td>23.99</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.990</td>\n",
       "      <td>Mayhaw_Week 10.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>876023</td>\n",
       "      <td>Georgia-Pacific Corporation - Cedar Springs Pa...</td>\n",
       "      <td>PPW</td>\n",
       "      <td>28.16</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28.160</td>\n",
       "      <td>Mayhaw_Week 10.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>876026</td>\n",
       "      <td>Georgia-Pacific Corporation - Cedar Springs Pa...</td>\n",
       "      <td>PPW</td>\n",
       "      <td>28.04</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28.040</td>\n",
       "      <td>Mayhaw_Week 10.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>WRR210317XXXX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>300140</td>\n",
       "      <td>Georgia-Pacific - Cedar Springs Paper Mill</td>\n",
       "      <td>PPW</td>\n",
       "      <td>27.47</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.470</td>\n",
       "      <td>W6_Updated_Mayhaw 122-1 ST 1 WE 08.03.24.1.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>WRR240404TH02</td>\n",
       "      <td>Week05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>300165</td>\n",
       "      <td>Georgia-Pacific - Cedar Springs Paper Mill</td>\n",
       "      <td>PPW</td>\n",
       "      <td>29.26</td>\n",
       "      <td>0.000</td>\n",
       "      <td>29.260</td>\n",
       "      <td>W6_Updated_Mayhaw 122-1 ST 1 WE 08.03.24.1.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>WRR240404TH02</td>\n",
       "      <td>Week05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>141578</td>\n",
       "      <td>Georgia-Pacific - Albany Lumber</td>\n",
       "      <td>CNS</td>\n",
       "      <td>25.40</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25.400</td>\n",
       "      <td>W6_Updated_Mayhaw 122-1 ST 1 WE 08.03.24.1.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>WRR240404TH02</td>\n",
       "      <td>Week05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>141866</td>\n",
       "      <td>Georgia-Pacific - Albany Lumber</td>\n",
       "      <td>CNS</td>\n",
       "      <td>25.47</td>\n",
       "      <td>0.228</td>\n",
       "      <td>25.242</td>\n",
       "      <td>W6_Updated_Mayhaw 122-1 ST 1 WE 08.03.24.1.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>WRR240404TH02</td>\n",
       "      <td>Week05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2024-08-02</td>\n",
       "      <td>142046</td>\n",
       "      <td>Georgia-Pacific - Albany Lumber</td>\n",
       "      <td>CNS</td>\n",
       "      <td>27.12</td>\n",
       "      <td>0.220</td>\n",
       "      <td>26.900</td>\n",
       "      <td>W6_Updated_Mayhaw 122-1 ST 1 WE 08.03.24.1.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>WRR240404TH02</td>\n",
       "      <td>Week05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8962 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Ticket                                               Mill  \\\n",
       "0   2021-07-06  875937  Georgia-Pacific Corporation - Cedar Springs Pa...   \n",
       "1   2021-07-06  875841  Georgia-Pacific Corporation - Cedar Springs Pa...   \n",
       "2   2021-07-06  875787  Georgia-Pacific Corporation - Cedar Springs Pa...   \n",
       "3   2021-07-06  876023  Georgia-Pacific Corporation - Cedar Springs Pa...   \n",
       "4   2021-07-06  876026  Georgia-Pacific Corporation - Cedar Springs Pa...   \n",
       "..         ...     ...                                                ...   \n",
       "280 2024-08-01  300140         Georgia-Pacific - Cedar Springs Paper Mill   \n",
       "281 2024-08-01  300165         Georgia-Pacific - Cedar Springs Paper Mill   \n",
       "282 2024-07-29  141578                    Georgia-Pacific - Albany Lumber   \n",
       "283 2024-08-01  141866                    Georgia-Pacific - Albany Lumber   \n",
       "284 2024-08-02  142046                    Georgia-Pacific - Albany Lumber   \n",
       "\n",
       "    Product  Tons (U.S)  Cull Tons  Accepted Tons  \\\n",
       "0       PPW       23.27      0.000         23.270   \n",
       "1       PPW       23.86      0.000         23.860   \n",
       "2       PPW       23.99      0.000         23.990   \n",
       "3       PPW       28.16      0.000         28.160   \n",
       "4       PPW       28.04      0.000         28.040   \n",
       "..      ...         ...        ...            ...   \n",
       "280     PPW       27.47      0.000         27.470   \n",
       "281     PPW       29.26      0.000         29.260   \n",
       "282     CNS       25.40      0.000         25.400   \n",
       "283     CNS       25.47      0.228         25.242   \n",
       "284     CNS       27.12      0.220         26.900   \n",
       "\n",
       "                                             Source Notes  Reporting Period  \\\n",
       "0                                Mayhaw_Week 10.pdf   NaN               5.0   \n",
       "1                                Mayhaw_Week 10.pdf   NaN               5.0   \n",
       "2                                Mayhaw_Week 10.pdf   NaN               5.0   \n",
       "3                                Mayhaw_Week 10.pdf   NaN               5.0   \n",
       "4                                Mayhaw_Week 10.pdf   NaN               5.0   \n",
       "..                                              ...   ...               ...   \n",
       "280  W6_Updated_Mayhaw 122-1 ST 1 WE 08.03.24.1.pdf   NaN               8.0   \n",
       "281  W6_Updated_Mayhaw 122-1 ST 1 WE 08.03.24.1.pdf   NaN               8.0   \n",
       "282  W6_Updated_Mayhaw 122-1 ST 1 WE 08.03.24.1.pdf   NaN               8.0   \n",
       "283  W6_Updated_Mayhaw 122-1 ST 1 WE 08.03.24.1.pdf   NaN               8.0   \n",
       "284  W6_Updated_Mayhaw 122-1 ST 1 WE 08.03.24.1.pdf   NaN               8.0   \n",
       "\n",
       "          TicketID    Week  \n",
       "0    WRR210317XXXX     NaN  \n",
       "1    WRR210317XXXX     NaN  \n",
       "2    WRR210317XXXX     NaN  \n",
       "3    WRR210317XXXX     NaN  \n",
       "4    WRR210317XXXX     NaN  \n",
       "..             ...     ...  \n",
       "280  WRR240404TH02  Week05  \n",
       "281  WRR240404TH02  Week05  \n",
       "282  WRR240404TH02  Week05  \n",
       "283  WRR240404TH02  Week05  \n",
       "284  WRR240404TH02  Week05  \n",
       "\n",
       "[8962 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mill_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the old Harvest TicketIDs\n",
    "harvested_tons_oldTID = mill_df[mill_df['Reporting Period'] == 7].groupby(\"TicketID\")['Tons (U.S)'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63343.458"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harvested_tons_oldTID['Tons (U.S)'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get new and old TIDs that are currently in process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting harvest ids that were in RP 7 and are still \"Active\" (Potentially need updating due to harvest)\n",
    "harvest_activities = wrr_df[(wrr_df['Reporting Period'] == 7) & (wrr_df['Status'].isin(['IN PROCESS', \"POST\"]))]['UniqueID'].unique().tolist()\n",
    "harvest_old_ticketid = wrr_df[(wrr_df['Reporting Period'] == 7) & (wrr_df['Status'].isin(['IN PROCESS', \"POST\"]))]['TicketID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4989.77"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how many tons are under old TIDs of activities in question\n",
    "harvested_tons_oldTID[harvested_tons_oldTID['TicketID'].isin(harvest_old_ticketid)]['Tons (U.S)'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the new TIDs based on these harvest activities\n",
    "new_ticketIDs = ticketid_table[ticketid_table['UniqueID'].isin(harvest_activities)]['TicketID'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what is in old_ticketid that is not in new_ticketIDs\n",
    "[item for item in harvest_old_ticketid if item not in new_ticketIDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in harvest_old_ticketid:\n",
    "    old_unique = wrr_df[wrr_df['TicketID'] == id]['UniqueID'].unique().tolist()\n",
    "    new_unique = ticketid_table[ticketid_table['TicketID'] == id]['UniqueID'].unique().tolist()\n",
    "    inold_notinew = [item for item in old_unique if item not in new_unique]\n",
    "    if len(inold_notinew) > 0:\n",
    "        print(id, old_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_expected = pd.merge(ticketid_table, wrr_df[['UniqueID', 'Current RP Expected GT', 'Status', 'Future GT']], on='UniqueID', how='left')\n",
    "trial_expected = pd.merge(trial_expected, client_df[['UniqueID', 'Reporting Period']], on='UniqueID', how='left')\n",
    "wrr_rp7_expected = trial_expected[(trial_expected['Reporting Period'] == 7) & trial_expected['Status'].isin(['IN PROCESS', 'OPEN', 'POST'])].groupby('TicketID')['Current RP Expected GT'].sum().reset_index()\n",
    "wrr_rp7_expected = pd.merge(wrr_rp7_expected, harvested_tons_oldTID, on='TicketID', how='left')\n",
    "wrr_rp7_expected['Tons (U.S)'] = pd.to_numeric(wrr_rp7_expected['Tons (U.S)'], errors='coerce', downcast='float')\n",
    "wrr_rp7_expected['Current RP Expected GT'] = pd.to_numeric(wrr_rp7_expected['Current RP Expected GT'], errors='coerce', downcast='float')\n",
    "wrr_rp7_expected['Tons (U.S)'].fillna(0, inplace=True)\n",
    "wrr_rp7_expected['Current RP Expected GT'].fillna(0, inplace=True)\n",
    "wrr_rp7_expected['Remaining'] = wrr_rp7_expected['Current RP Expected GT'] - wrr_rp7_expected['Tons (U.S)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TicketID</th>\n",
       "      <th>Current RP Expected GT</th>\n",
       "      <th>Tons (U.S)</th>\n",
       "      <th>Remaining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WRR230829CC04</td>\n",
       "      <td>252.679993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>252.679993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WRR231107CC02</td>\n",
       "      <td>9338.919922</td>\n",
       "      <td>4852.720215</td>\n",
       "      <td>4486.199707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WRR231107TT01</td>\n",
       "      <td>1648.609985</td>\n",
       "      <td>137.050003</td>\n",
       "      <td>1511.559937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WRR240101CCXX</td>\n",
       "      <td>12298.480469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12298.480469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WRR240101TH01</td>\n",
       "      <td>541.820007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>541.820007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WRR240101TH02</td>\n",
       "      <td>888.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>888.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WRR240101TT01</td>\n",
       "      <td>999.900024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>999.900024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WRR240404TH01</td>\n",
       "      <td>920.400024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>920.400024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WRR240404TH02</td>\n",
       "      <td>2090.399902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2090.399902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>WRR240517TH01</td>\n",
       "      <td>5916.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5916.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TicketID  Current RP Expected GT   Tons (U.S)     Remaining\n",
       "0   WRR230829CC04              252.679993     0.000000    252.679993\n",
       "1   WRR231107CC02             9338.919922  4852.720215   4486.199707\n",
       "2   WRR231107TT01             1648.609985   137.050003   1511.559937\n",
       "8   WRR240101CCXX            12298.480469     0.000000  12298.480469\n",
       "9   WRR240101TH01              541.820007     0.000000    541.820007\n",
       "10  WRR240101TH02              888.250000     0.000000    888.250000\n",
       "11  WRR240101TT01              999.900024     0.000000    999.900024\n",
       "12  WRR240404TH01              920.400024     0.000000    920.400024\n",
       "13  WRR240404TH02             2090.399902     0.000000   2090.399902\n",
       "14  WRR240517TH01             5916.000000     0.000000   5916.000000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrr_rp7_expected[wrr_rp7_expected['Remaining'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrr_rp7_expected.to_excel(\"wrr_rp7_accouting.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postgres_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
