{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from smartsheet_dataframe import get_as_df\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing Smartsheet information in variables\n",
    "shitz_token = \"wMvGniITjDFd7ClZPE44wtJGvZkM7Hg7mP7if\" #Bily's personal token to access G-A smartsheet data. Anyone can obtain their own token\n",
    "fhaid = 4523924143794052 # The ID number that references the FHA sheet\n",
    "mssid = 3005704744265604 # The ID number that references the MSS sheet\n",
    "\n",
    "# Creating the FHA and MSS dataframes\n",
    "fha_df = get_as_df(type_='sheet',\n",
    "                  token=shitz_token,\n",
    "                  id_=fhaid)\n",
    "\n",
    "mss_df = get_as_df(type_='sheet',\n",
    "                  token=shitz_token,\n",
    "                  id_=mssid)\n",
    "\n",
    "data_df = mss_df.loc[(mss_df['UniqueID'].str.contains('WAR')) |\n",
    "                     (mss_df['UniqueID'].str.contains('WRR')) |\n",
    "                     (mss_df['UniqueID'].str.contains('BJT'))].copy()\n",
    "\n",
    "data_df['Tract'] = data_df['Tract'].astype(str).apply(lambda x: x.split('.')[0])\n",
    "data_df['CMP'] = data_df['CMP'].astype(str).apply(lambda x: x.split('.')[0])\n",
    "data_df['Stand'] = data_df['Stand'].astype(str).apply(lambda x: x.split('.')[0])\n",
    "data_df['TCS'] = data_df['Tract'] + \"_\" + data_df['CMP'] + \"_\" + data_df['Stand']\n",
    "\n",
    "data_df['Reporting Period'] = data_df['Reporting Period'].fillna(0)\n",
    "data_df.loc[data_df['Reporting Period'] == \"\", 'Reporting Period'] = 0\n",
    "s = data_df.loc[pd.to_numeric(data_df['Reporting Period'], errors='coerce').isnull() & data_df['Reporting Period'].str.contains(\"RP\"), 'Reporting Period'].apply(lambda x: x.strip()[-1])\n",
    "data_df['trial'] = data_df.index.map(s)\n",
    "data_df.loc[pd.to_numeric(data_df['Reporting Period'], errors='coerce').isnull() & data_df['Reporting Period'].str.contains(\"RP\"), 'Reporting Period'] = data_df.loc[pd.to_numeric(data_df['Reporting Period'], errors='coerce').isnull() & data_df['Reporting Period'].str.contains(\"RP\"), 'trial']\n",
    "data_df['Reporting Period'] = pd.to_numeric(data_df['Reporting Period'], downcast='integer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creaet Client Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the Client Provided data and make sure the fields are similar\n",
    "client_df = data_df[['UniqueID',\n",
    "                    'Tract',\n",
    "                    'CMP',\n",
    "                    'Stand',\n",
    "                    'Acres',\n",
    "                    'Age',\n",
    "                    'County',\n",
    "                    'State',\n",
    "                    'Stand Type',\n",
    "                    'Origin',\n",
    "                    'Scheduled',\n",
    "                    'PreBA',\n",
    "                    'PreTPA',\n",
    "                    'PreGTA',\n",
    "                    'PlnBA',\n",
    "                    'PlnTPA',\n",
    "                    'PlnGTA',\n",
    "                    'Client GT',\n",
    "                    'Future GT',\n",
    "                    'Reporting Period']].copy()\n",
    "\n",
    "client_df['Age'] = pd.to_numeric(client_df['Age'], errors='coerce', downcast='integer').fillna(0).astype(int)\n",
    "client_df.loc[pd.to_numeric(client_df['Future GT'], errors='coerce').isnull(), 'Future GT'] = 0\n",
    "client_df['Tract'] = client_df['Tract'].astype(str)\n",
    "client_df['Stand'] = client_df['Stand'].astype(str)\n",
    "client_df['Tract'] = client_df['Tract'].apply(lambda x: x.split('.')[0])\n",
    "client_df['Client GT'] = pd.to_numeric(client_df['Client GT'], errors=\"coerce\")\n",
    "client_df['Client GT'] = client_df['Client GT'].fillna(0)\n",
    "\n",
    "cols = ['PreBA', 'PreTPA', 'PreGTA', 'PlnBA', 'PlnTPA', 'PlnGTA']\n",
    "\n",
    "for x in cols:\n",
    "    client_df[x] = pd.to_numeric(client_df[x], errors='coerce', downcast='integer').fillna(-99).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Normalize some of the fields in the client intake table\n",
    "\n",
    "## Normalize Species\n",
    "species = [\"Slash Pine\", \"Loblolly Pine\", 'Mixed Natural Pine', 'Hardwood Mix', 'Pine Straw', \"Other\"]\n",
    "species_dict = {'Species': species}\n",
    "species_df = pd.DataFrame(species_dict)\n",
    "species_df['SpeciesUID'] = species_df.index\n",
    "\n",
    "def species_map(x):\n",
    "    x = x.lower()\n",
    "    if \"slash\" in x:\n",
    "        return 0\n",
    "    elif \"loblol\" in x:\n",
    "        return 1\n",
    "    elif \"mixed natural\" in x:\n",
    "        return 2\n",
    "    elif \"h\" in x:\n",
    "        return 3\n",
    "    elif \"straw\" in x:\n",
    "        return 4\n",
    "    elif \"pine\" in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 5\n",
    "    \n",
    "client_df['Stand Type'] = client_df['Stand Type'].apply(lambda x: species_map(x))\n",
    "\n",
    "## Normalize origin\n",
    "origins = ['Planted', 'Natural', 'Natural Mix', 'Other']\n",
    "origin_dict = {'Origin': origins}\n",
    "origin_df = pd.DataFrame(origin_dict)\n",
    "origin_df['OriginUID'] = origin_df.index\n",
    "\n",
    "def origin_map(x):\n",
    "    x = x.lower()\n",
    "    if \"plant\" in x:\n",
    "        return 0\n",
    "    elif \"natural mix\" in x:\n",
    "        return 2\n",
    "    elif \"nat\" in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 3\n",
    "client_df['Origin'] = client_df['Origin'].apply(lambda x: origin_map(x))\n",
    "\n",
    "\n",
    "## Normalize tract\n",
    "client_df['tract_l'] = client_df['Tract'].apply(lambda x: x.lower())\n",
    "tracts = client_df['tract_l'].unique().tolist()\n",
    "tract_dict = {'tract': tracts}\n",
    "tract_df = pd.DataFrame(tract_dict)\n",
    "tract_df['tract_oid'] = tract_df.index\n",
    "new_tract_dict = dict(zip(tract_df['tract'], tract_df['tract_oid']))\n",
    "client_df['Tract'] = client_df['tract_l'].map(new_tract_dict)\n",
    "\n",
    "## Normalize county\n",
    "client_df['County'] = client_df['County'].astype(str)\n",
    "client_df['county_l'] = client_df['County'].apply(lambda x: x.lower())\n",
    "countys = client_df['county_l'].unique().tolist()\n",
    "county_dict = {'county': countys}\n",
    "county_df = pd.DataFrame(county_dict)\n",
    "county_df['county_oid'] = county_df.index\n",
    "new_county_dict = dict(zip(county_df['county'], county_df['county_oid']))\n",
    "client_df['County'] = client_df['county_l'].map(new_county_dict)\n",
    "\n",
    "## Normalize state\n",
    "client_df['State'] = client_df['State'].astype(str)\n",
    "client_df['state_l'] = client_df['State'].apply(lambda x: x.lower())\n",
    "states = client_df['state_l'].unique().tolist()\n",
    "state_dict = {'state': states}\n",
    "state_df = pd.DataFrame(state_dict)\n",
    "state_df['state_oid'] = state_df.index\n",
    "new_state_dict = dict(zip(state_df['state'], state_df['state_oid']))\n",
    "client_df['State'] = client_df['state_l'].map(new_state_dict)\n",
    "\n",
    "# Drop the lowercase columns\n",
    "client_df.drop(columns=['tract_l', 'county_l', 'state_l'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GA Intake Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_intake_df = data_df[['IntakeID',\n",
    "                       'FolderID',\n",
    "                       'UniqueID',\n",
    "                       'GA_ACRES',\n",
    "                       'GA GT', # this is going to be GA total isn't it? Or does it stay as GA estimate of current GT (total minus what client says is future)\n",
    "                       'Total GT', # This will be the conservative total between client and GA numbers\n",
    "                       'Notes'\n",
    "                       ]].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Status Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_df = data_df[['UniqueID',\n",
    "                    'Guidance',\n",
    "                    'Expiration',\n",
    "                    'GuidanceProvider',\n",
    "                    'Status',\n",
    "                    'Completed Date'\n",
    "                    ]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TicketID -> UniqueID lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticketid_lookup_df = data_df[['UniqueID', 'TicketID']].copy() # the uniqueid will the the unique id for this table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticketid_list = data_df['TicketID'].unique().tolist()\n",
    "ticketid_dict = {'ticketid': ticketid_list}\n",
    "ticketid_df = pd.DataFrame(ticketid_dict)\n",
    "ticketid_df['ticketid_oid'] = ticketid_df.index\n",
    "new_ticketid_dict = dict(zip(ticketid_df['ticketid'], ticketid_df['ticketid_oid']))\n",
    "ticketid_lookup_df['ticketid'] = ticketid_lookup_df['TicketID'].map(new_ticketid_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the TCS lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcs_df = data_df.groupby('TicketID').agg({'Tract': 'first',\n",
    "                                               'CMP': 'first',\n",
    "                                               'Stand': ', '.join}).reset_index()\n",
    "\n",
    "def split_stands(x):\n",
    "    bugger_splot = list(set(x.split(', ')))\n",
    "    bugger_splot.sort()\n",
    "    return \", \".join(bugger_splot)\n",
    "    \n",
    "tcs_df['stands'] = tcs_df['Stand'].apply(split_stands)\n",
    "tcs_df['comp'] = tcs_df['CMP'].apply(lambda x: x if x!=\"NP\" else \"\")\n",
    "tcs_df['TCS'] = tcs_df['Tract'] + \"_\" + tcs_df['comp'] + \"_\" + tcs_df['stands']\n",
    "tcs_df['tcs_oid'] = tcs_df.index\n",
    "tcs_df = tcs_df[['tcs_oid', 'TicketID', 'TCS']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TicketID table should have a link to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcs_mapper = dict(zip(tcs_df['TicketID'], tcs_df['tcs_oid']))\n",
    "ticketid_df['tcs'] = ticketid_df['ticketid'].map(tcs_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticketid</th>\n",
       "      <th>ticketid_oid</th>\n",
       "      <th>tcs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ticketid, ticketid_oid, tcs]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticketid_df[ticketid_df['tcs'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mill Ticket sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "projs = ['WAR', 'WRR', 'BJT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\\Mill Tickets\\ARCHIVE\\WAR_RP6\n",
      "WAR_RP6_Compiled.xlsm\n",
      "P:\\Mill Tickets\\ARCHIVE\\WAR_RP7\n",
      "WAR_RP7_Compiled.xlsm\n",
      "P:\\Mill Tickets\\ARCHIVE\\WAR_RP8\n",
      "WAR_RP8_Compiled.xlsm\n",
      "P:\\Mill Tickets\\Retroactive_Ticket_imageing\\WAR\\WAR_RP2\n",
      "WAR_RP2_Compiled.xlsm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bbrown\\Anaconda3\\envs\\postgres_python\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\\Mill Tickets\\Retroactive_Ticket_imageing\\WAR\\WAR_RP3\n",
      "WAR_RP3_Compiled.xlsm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bbrown\\Anaconda3\\envs\\postgres_python\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\\Mill Tickets\\Retroactive_Ticket_imageing\\WAR\\WAR_RP4\n",
      "WAR_RP4_Compiled.xlsm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bbrown\\Anaconda3\\envs\\postgres_python\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\\Mill Tickets\\Retroactive_Ticket_imageing\\WAR\\WAR_RP5\n",
      "WAR_RP5_Compiled.xlsm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bbrown\\Anaconda3\\envs\\postgres_python\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\\Mill Tickets\\WAR_RP9\n",
      "WAR_RP9_Compiled.xlsm\n",
      "P:\\Mill Tickets\\ARCHIVE\\WRR_RP5\n",
      "WRR_RP5_Compiled.xlsm\n",
      "P:\\Mill Tickets\\ARCHIVE\\WRR_RP6\n",
      "WRR_RP6_Compiled.xlsm\n",
      "P:\\Mill Tickets\\ARCHIVE\\WRR_RP7\n",
      "WRR_RP7_Compiled.xlsm\n",
      "P:\\Mill Tickets\\WRR_RP8\n",
      "WRR_RP8_Compiled.xlsm\n",
      "P:\\Mill Tickets\\ARCHIVE\\BJT_RP5\n",
      "BJT_RP5_Compiled.xlsm\n",
      "P:\\Mill Tickets\\ARCHIVE\\BJT_RP6\n",
      "BJT_RP6_Compiled.xlsm\n",
      "P:\\Mill Tickets\\ARCHIVE\\BJT_RP7\n",
      "BJT_RP7_Compiled.xlsm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbrown\\AppData\\Local\\Temp\\ipykernel_7204\\2111848845.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  big_df = pd.concat([big_df, df])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\\Mill Tickets\\BJT_RP8\n",
      "BJT_RP8_Compiled.xlsm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    big_df.loc[big_df[\\'Tons (U.S)\\'].isnull(), \\'Tons (U.S)\\'] = big_df.loc[big_df[\\'Tons (U.S)\\'].isnull(), \\'TonsUS\\']\\n    big_df[\\'Cull Tons\\'].fillna(big_df[\\'CullTons\\'], inplace=True)\\n    big_df[\\'Accepted Tons\\'].fillna(big_df[\\'AcceptedTons\\'], inplace=True)\\n    big_df[\\'Reporting Period\\'].fillna(big_df[\\'ReportingPeriod\\'],inplace=True)\\n\\n    def rep_fix(x):\\n        if \"RP\" in str(x):\\n            return x[-1]\\n        else:\\n            return x\\n        \\n    big_df[\\'Reporting Period\\'] = big_df[\\'Reporting Period\\'].apply(lambda x: rep_fix(x))\\n    big_df[\\'Reporting Period\\'] = pd.to_numeric(big_df[\\'Reporting Period\\'])\\n\\n    big_df[\\'Date\\'] = pd.to_datetime(big_df[\\'Date\\'])\\n\\n    harvest_df = big_df[[\\'Date\\',\\n                    \\'Ticket\\',\\n                    \\'Mill\\',\\n                    \\'Product\\',\\n                    \\'Tons (U.S)\\',\\n                    \\'Cull Tons\\',\\n                    \\'Accepted Tons\\',\\n                    \\'Source\\',\\n                    \\'Notes\\',\\n                    \\'Reporting Period\\',\\n                    \\'TicketID\\',\\n                    \\'Week\\']].copy()\\n\\n    harvest_df = harvest_df.drop_duplicates()\\n    '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mill_loc = r\"P:\\Mill Tickets\"\n",
    "mega_df = pd.DataFrame()\n",
    "\n",
    "for proj in projs:\n",
    "    file_pattern = f\"{proj}_RP*_Compiled.xlsm\"\n",
    "    big_df = pd.DataFrame()\n",
    "\n",
    "    mill_name = []\n",
    "    for root, dirs, files in os.walk(mill_loc):\n",
    "        for file in files:\n",
    "            if f\"{proj}_RP\" in file and file.endswith(\"Compiled.xlsm\"):\n",
    "                if \"$\" in file:\n",
    "                    pass\n",
    "                else:\n",
    "                    print(root)\n",
    "                    print(file)\n",
    "                    df = pd.read_excel(os.path.join(root, file), sheet_name='RP_Project')\n",
    "                    big_df = pd.concat([big_df, df])\n",
    "    mega_df = pd.concat([mega_df, big_df])\n",
    "                    \n",
    "'''\n",
    "    big_df.loc[big_df['Tons (U.S)'].isnull(), 'Tons (U.S)'] = big_df.loc[big_df['Tons (U.S)'].isnull(), 'TonsUS']\n",
    "    big_df['Cull Tons'].fillna(big_df['CullTons'], inplace=True)\n",
    "    big_df['Accepted Tons'].fillna(big_df['AcceptedTons'], inplace=True)\n",
    "    big_df['Reporting Period'].fillna(big_df['ReportingPeriod'],inplace=True)\n",
    "\n",
    "    def rep_fix(x):\n",
    "        if \"RP\" in str(x):\n",
    "            return x[-1]\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    big_df['Reporting Period'] = big_df['Reporting Period'].apply(lambda x: rep_fix(x))\n",
    "    big_df['Reporting Period'] = pd.to_numeric(big_df['Reporting Period'])\n",
    "\n",
    "    big_df['Date'] = pd.to_datetime(big_df['Date'])\n",
    "\n",
    "    harvest_df = big_df[['Date',\n",
    "                    'Ticket',\n",
    "                    'Mill',\n",
    "                    'Product',\n",
    "                    'Tons (U.S)',\n",
    "                    'Cull Tons',\n",
    "                    'Accepted Tons',\n",
    "                    'Source',\n",
    "                    'Notes',\n",
    "                    'Reporting Period',\n",
    "                    'TicketID',\n",
    "                    'Week']].copy()\n",
    "\n",
    "    harvest_df = harvest_df.drop_duplicates()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df.loc[mega_df['Tons (U.S)'].isnull(), 'Tons (U.S)'] = mega_df.loc[mega_df['Tons (U.S)'].isnull(), 'TonsUS']\n",
    "mega_df['Cull Tons'].fillna(mega_df['CullTons'], inplace=True)\n",
    "mega_df['Accepted Tons'].fillna(mega_df['AcceptedTons'], inplace=True)\n",
    "mega_df['Reporting Period'].fillna(mega_df['ReportingPeriod'],inplace=True)\n",
    "\n",
    "def rep_fix(x):\n",
    "    if \"RP\" in str(x):\n",
    "        return x[-1]\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "mega_df['Reporting Period'] = mega_df['Reporting Period'].apply(lambda x: rep_fix(x))\n",
    "mega_df['Reporting Period'] = pd.to_numeric(mega_df['Reporting Period'])\n",
    "\n",
    "mega_df['Date'] = pd.to_datetime(mega_df['Date'])\n",
    "\n",
    "harvest_df = mega_df[['Date',\n",
    "                'Ticket',\n",
    "                'Mill',\n",
    "                'Product',\n",
    "                'Tons (U.S)',\n",
    "                'Cull Tons',\n",
    "                'Accepted Tons',\n",
    "                'Source',\n",
    "                'Notes',\n",
    "                'Reporting Period',\n",
    "                'TicketID',\n",
    "                'Week']].copy()\n",
    "\n",
    "harvest_df = harvest_df.drop_duplicates()\n",
    "harvest_df.loc[harvest_df['TicketID'] == 'WAR18051XXXX', 'TicketID'] = 'WAR180518XXXX' # Found some mislabeled tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mill_list = harvest_df['Mill'].unique().tolist()\n",
    "mill_dict = {}\n",
    "mill_dict['mill'] = mill_list\n",
    "mill_df = pd.DataFrame(mill_dict)\n",
    "mill_df['mill_uid'] = mill_df.index\n",
    "mill_mapper = dict(zip(mill_df['mill'], mill_df['mill_uid']))\n",
    "harvest_df['mill'] = harvest_df['Mill'].map(mill_mapper)\n",
    "harvest_df.drop(columns=['Mill'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvest_df['Week'] = harvest_df['Week'].astype(str)\n",
    "harvest_df.loc[harvest_df['Week'] == 'Week3b', 'Week'] = \"3\"\n",
    "def weeker(week):\n",
    "    if \"Week\" in week:\n",
    "        x = week.split(\"k\")[1]\n",
    "        x = int(x)\n",
    "        return x\n",
    "    elif \"nan\" in week:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(week)\n",
    "    \n",
    "harvest_df['Week_trial'] = harvest_df['Week'].apply(lambda x: weeker(x))\n",
    "\n",
    "week_list = harvest_df['Week_trial'].unique().tolist()\n",
    "week_dict = {}\n",
    "week_dict['week'] = week_list\n",
    "week_df = pd.DataFrame(week_dict)\n",
    "week_df['week_uid'] = week_df.index\n",
    "week_mapper = dict(zip(week_df['week'], week_df['week_uid']))\n",
    "harvest_df['week'] = harvest_df['Week_trial'].map(week_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = harvest_df['Product'].unique().tolist()\n",
    "product_dict = {}\n",
    "product_dict['product'] = product_list\n",
    "product_df = pd.DataFrame(product_dict)\n",
    "product_df['product_uid'] = product_df.index\n",
    "product_mapper = dict(zip(product_df['product'], product_df['product_uid']))\n",
    "harvest_df['product'] = harvest_df['Product'].map(product_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>total_tons</th>\n",
       "      <th>Cull Tons</th>\n",
       "      <th>Accepted Tons</th>\n",
       "      <th>Source</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Reporting Period</th>\n",
       "      <th>mill</th>\n",
       "      <th>Week_trial</th>\n",
       "      <th>week</th>\n",
       "      <th>product</th>\n",
       "      <th>ticketid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>160048</td>\n",
       "      <td>26.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.31</td>\n",
       "      <td>M-82_Week 1.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>160157</td>\n",
       "      <td>25.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.79</td>\n",
       "      <td>M-82_Week 1.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>160120</td>\n",
       "      <td>25.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.32</td>\n",
       "      <td>M-82_Week 1.pdf</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>160155</td>\n",
       "      <td>25.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.31</td>\n",
       "      <td>M-82_Week 1.pdf</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>160082</td>\n",
       "      <td>27.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.17</td>\n",
       "      <td>M-82_Week 1.pdf</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2024-07-15</td>\n",
       "      <td>21640715</td>\n",
       "      <td>30.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.05</td>\n",
       "      <td>2024BJT39wk2.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>21644553</td>\n",
       "      <td>32.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.88</td>\n",
       "      <td>2024BJT39wk2.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>21644635</td>\n",
       "      <td>26.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.47</td>\n",
       "      <td>2024BJT39wk2.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>21643437</td>\n",
       "      <td>32.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.48</td>\n",
       "      <td>2024BJT39wk2.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>21645207</td>\n",
       "      <td>28.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.84</td>\n",
       "      <td>2024BJT39wk2.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46578 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date    Ticket  total_tons  Cull Tons  Accepted Tons  \\\n",
       "0   2021-08-02    160048       26.31        0.0          26.31   \n",
       "1   2021-08-03    160157       25.79        0.0          25.79   \n",
       "2   2021-08-03    160120       25.32        0.0          25.32   \n",
       "3   2021-08-03    160155       25.31        0.0          25.31   \n",
       "4   2021-08-03    160082       27.17        0.0          27.17   \n",
       "..         ...       ...         ...        ...            ...   \n",
       "228 2024-07-15  21640715       30.05        0.0          30.05   \n",
       "229 2024-07-24  21644553       32.88        0.0          32.88   \n",
       "230 2024-07-24  21644635       26.47        0.0          26.47   \n",
       "231 2024-07-22  21643437       32.48        0.0          32.48   \n",
       "232 2024-07-25  21645207       28.84        0.0          28.84   \n",
       "\n",
       "               Source Notes  Reporting Period  mill  Week_trial  week  \\\n",
       "0     M-82_Week 1.pdf   NaN                 6     0           1     0   \n",
       "1     M-82_Week 1.pdf   NaN                 6     0           1     0   \n",
       "2     M-82_Week 1.pdf                       6     0           1     0   \n",
       "3     M-82_Week 1.pdf                       6     0           1     0   \n",
       "4     M-82_Week 1.pdf                       6     0           1     0   \n",
       "..                ...   ...               ...   ...         ...   ...   \n",
       "228  2024BJT39wk2.pdf   NaN                 8    40           4     6   \n",
       "229  2024BJT39wk2.pdf   NaN                 8    40           4     6   \n",
       "230  2024BJT39wk2.pdf   NaN                 8    40           4     6   \n",
       "231  2024BJT39wk2.pdf   NaN                 8    40           4     6   \n",
       "232  2024BJT39wk2.pdf   NaN                 8    40           4     6   \n",
       "\n",
       "     product  ticketid  \n",
       "0          0       375  \n",
       "1          0       375  \n",
       "2          0       375  \n",
       "3          0       375  \n",
       "4          0       375  \n",
       "..       ...       ...  \n",
       "228        0       432  \n",
       "229        0       432  \n",
       "230        0       432  \n",
       "231        0       432  \n",
       "232        0       432  \n",
       "\n",
       "[46578 rows x 13 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticket_id_mapper = dict(zip(ticketid_df['ticketid'], ticketid_df['ticketid_oid']))\n",
    "harvest_df['ticketid'] = harvest_df['TicketID'].map(ticket_id_mapper)\n",
    "harvest_df['ticketid'] = harvest_df['ticketid'].astype(int)\n",
    "harvest_df.drop(columns=['Product', 'TicketID', 'Week'],inplace=True)\n",
    "harvest_df.rename(columns={'Tons (U.S)': 'total_tons'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to make the Expected Tons / RP table\n",
    "\n",
    "\n",
    "My plan:\n",
    "- Get the previous RP expected simply from MSS \n",
    "- Current RP pull from files I made for Rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following should get me up to RP8 for WAR\n",
    "war_expected_inprog = data_df[(~data_df['Reporting Period'].isna()) & (data_df['UniqueID'].str.contains(\"WAR\"))].copy()\n",
    "war_expected_inprog = war_expected_inprog[war_expected_inprog['Reporting Period'] != 9]\n",
    "war_expected_inprog = war_expected_inprog[['TicketID', 'Reporting Period', 'Current RP Expected GT']]\n",
    "war_expected_inprog = war_expected_inprog[war_expected_inprog['Current RP Expected GT'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_expected_rp9 = pd.read_excel(r\"./WAR_RP9_InProcess/Excel_sheets/rp9_investigate_matchesRob.xlsx\", sheet_name='Sheet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TicketID</th>\n",
       "      <th>RP9 Expected</th>\n",
       "      <th>Reporting Period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WAR230908XXXX</td>\n",
       "      <td>9019.00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WAR231107XXXX</td>\n",
       "      <td>12289.71</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WAR240521CCXX</td>\n",
       "      <td>9814.68</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WAR240521TN01</td>\n",
       "      <td>2918.65</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAR240521TT01</td>\n",
       "      <td>6756.53</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>WAR241025HD04</td>\n",
       "      <td>5186.26</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>WAR241025HD03</td>\n",
       "      <td>2700.00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>WAR241025HD02</td>\n",
       "      <td>8592.47</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>WAR241025HD01</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>WAR230318TXXX</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TicketID  RP9 Expected  Reporting Period\n",
       "0   WAR230908XXXX       9019.00                 9\n",
       "1   WAR231107XXXX      12289.71                 9\n",
       "2   WAR240521CCXX       9814.68                 9\n",
       "3   WAR240521TN01       2918.65                 9\n",
       "4   WAR240521TT01       6756.53                 9\n",
       "..            ...           ...               ...\n",
       "69  WAR241025HD04       5186.26                 9\n",
       "70  WAR241025HD03       2700.00                 9\n",
       "71  WAR241025HD02       8592.47                 9\n",
       "72  WAR241025HD01       1200.00                 9\n",
       "73  WAR230318TXXX          0.00                 9\n",
       "\n",
       "[74 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_expected_rp9['Reporting Period'] = 9\n",
    "war_expected_rp9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457641.09806425"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_expected_inprog.loc[war_expected_inprog['Reporting Period'] == 8, 'Current RP Expected GT'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postgres_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
